{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from face import FaceRecognizer, FaceDatabase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "photos_path = 'data/photos'\n",
    "embeddings_path = 'data/embeddings'\n",
    "face_recognizer = FaceRecognizer()\n",
    "face_database = FaceDatabase(embeddings_path)\n",
    "face_database.add(photos_path, face_recognizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to use (example for 2 frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from face import FaceRecognizer, FaceDatabase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_path = 'data/example.mp4'\n",
    "embeddings_path = 'data/embeddings'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "face_recognizer = FaceRecognizer()\n",
    "face_database = FaceDatabase(embeddings_path)\n",
    "face_recognizer.upload_database(face_database)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(video_path)\n",
    "if cap.isOpened():\n",
    "    ret, first_frame = cap.read()\n",
    "    ret, second_frame = cap.read()\n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Option 1. Detector + Encoder -> Detector + Encoder -> Detector + Encoder -> ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first frame\n",
    "bboxes, landmarks, confs = face_recognizer.detect(first_frame)\n",
    "embeddings = face_recognizer.encode(first_frame, landmarks)\n",
    "names = face_recognizer.identify(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# second frame\n",
    "bboxes, landmarks, confs = face_recognizer.detect(second_frame)\n",
    "embeddings = face_recognizer.encode(second_frame, landmarks)\n",
    "names = face_recognizer.identify(embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Option 2. Detector + Encoder -> OpticalFlowTracker -> OpticalFlowTracker -> ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from face import OpticalFlowTracker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first frame\n",
    "bboxes, landmarks, confs = face_recognizer.detect(first_frame)\n",
    "embeddings = face_recognizer.encode(first_frame, landmarks)\n",
    "names = face_recognizer.identify(embeddings)\n",
    "oft = OpticalFlowTracker(first_frame, bboxes, names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# second frame\n",
    "ret, bboxes, names = oft.track(second_frame)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Option 3. Detector + Encoder -> Detector + KalmanFilterTracker -> Detector + KalmanFilterTracker -> ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from face import KalmanFilterTracker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first frame\n",
    "bboxes, landmarks, confs = face_recognizer.detect(first_frame)\n",
    "embeddings = face_recognizer.encode(first_frame, landmarks)\n",
    "names = face_recognizer.identify(embeddings)\n",
    "kft = KalmanFilterTracker(bboxes, confs, names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# second frame\n",
    "bboxes, _, confs = face_recognizer.detect(second_frame)\n",
    "ret, bboxes, names = kft.track(bboxes, confs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to use (full video example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from face import FaceRecognizer, FaceDatabase, OpticalFlowTracker, KalmanFilterTracker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mode = 'detector_encoder'\n",
    "# mode = 'optical_flow_tracking'\n",
    "# mode = 'tracking_by_detection'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_path = 'data/example.mp4'\n",
    "embeddings_path = 'data/embeddings'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "face_recognizer = FaceRecognizer()\n",
    "face_database = FaceDatabase(embeddings_path)\n",
    "face_recognizer.upload_database(face_database)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(video_path)\n",
    "output_video_path = ''.join(video_path.split('.')[:-1]) + '_processed' + '.mp4'\n",
    "video_width, video_height, video_fps = int(cap.get(3)), int(cap.get(4)), int(cap.get(5))\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "writer = cv2.VideoWriter(output_video_path, fourcc, video_fps, (video_width, video_height))\n",
    "initialize = True\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    if not initialize:\n",
    "        if mode == 'optical_flow_tracking':\n",
    "            ret, bboxes, names = oft.track(frame)\n",
    "            if not ret:\n",
    "                initialize = True\n",
    "                print('OpticalFlowTracker cannot locate one of the targets in current frame')\n",
    "        elif mode == 'tracking_by_detection':\n",
    "            bboxes, _, confs = face_recognizer.detect(frame)\n",
    "            ret, bboxes, names = kft.track(bboxes, confs)\n",
    "            if not ret:\n",
    "                initialize = True\n",
    "                print('KalmanFilterTracker has located new unknown target')\n",
    "        elif mode == 'detector_encoder':\n",
    "            bboxes, landmarks, confs = face_recognizer.detect(frame)\n",
    "            embeddings = face_recognizer.encode(frame, landmarks)\n",
    "            names = face_recognizer.identify(embeddings)\n",
    "    if initialize:\n",
    "        bboxes, landmarks, confs = face_recognizer.detect(frame)\n",
    "        embeddings = face_recognizer.encode(frame, landmarks)\n",
    "        names = face_recognizer.identify(embeddings)\n",
    "        if mode == 'optical_flow_tracking':\n",
    "            oft = OpticalFlowTracker(frame, bboxes, names)\n",
    "        elif mode == 'tracking_by_detection':\n",
    "            kft = KalmanFilterTracker(bboxes, confs, names)\n",
    "        initialize = False\n",
    "    frame = face_recognizer.annotate(frame, bboxes, names=names)\n",
    "    cv2.imshow('Frame', frame)\n",
    "    if cv2.waitKey(0) == ord('q'):\n",
    "        break\n",
    "    writer.write(frame)\n",
    "cv2.destroyAllWindows()\n",
    "cap.release()\n",
    "writer.release()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
